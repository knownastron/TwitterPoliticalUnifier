{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from SQLConnection import LocalConnection\n",
    "from SQLConnection import AWSConnection\n",
    "sys.path.append('../databases')\n",
    "import mysql_aws_credentials as aws\n",
    "from Format import Format\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_conn = LocalConnection('../databases/main.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_conn = AWSConnection(aws.HOST, aws.PORT, aws.DATABASE_NAME, aws.USER, aws.PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_test_users = aws_conn.get_users_by_pol_label('conservative')\n",
    "libs_test_users = aws_conn.get_users_by_pol_label('liberal')\n",
    "cons_train_users = local_conn.get_users_by_pol_label('conservative')\n",
    "libs_train_users = local_conn.get_users_by_pol_label('liberal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cons_train_users.__len__())\n",
    "print(libs_train_users.__len__())\n",
    "cons_train_users[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = local_conn.get_all_tweets_by('sentedcruz')\n",
    "test_tweets1 = local_conn.get_all_tweets_by('aoc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = test_tweets[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/knownastron/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/knownastron/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(input_text):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    stopwords.add('it\\'s')\n",
    "    stopwords.add('w/')\n",
    "    stopwords.add('\\'s')\n",
    "    input_text_split = input_text.split()\n",
    "    output_text_split = [word for word in input_text_split if word not in stopwords]\n",
    "    return \" \".join(output_text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_tweet(tweet_text):    \n",
    "    tweet_text = tweet_text.lower()\n",
    "    tweet_text = Format.remove_hyperlinks(tweet_text)\n",
    "    tweet_text = Format.remove_picture_links(tweet_text)\n",
    "    tweet_text = Format.remove_hashtags(tweet_text)\n",
    "    tweet_text = Format.remove_mentions(tweet_text)\n",
    "    tweet_text = Format.remove_picture_links(tweet_text)\n",
    "    tweet_text = remove_stopwords(tweet_text)\n",
    "    tweet_text = tweet_text.translate(str.maketrans('','',string.punctuation + '—' + '“' + '…' + '\\’')) #remove punctuation\n",
    "    return tweet_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "denoised = []\n",
    "denoised1 = []\n",
    "for tweet in test_tweets:\n",
    "    denoised.append(denoise_tweet(tweet[1]))\n",
    "    \n",
    "for tweet in test_tweets1:\n",
    "    denoised1.append(denoise_tweet(tweet[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for i,d in enumerate(denoised):\n",
    "    tokens.extend(d.split())\n",
    "    \n",
    "tokens1 = []\n",
    "for i,d in enumerate(denoised1):\n",
    "    print(i, test_tweets1[i][1])\n",
    "    print('////')\n",
    "    print(d,'\\n')\n",
    "    tokens1.extend(d.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "count = collections.Counter(tokens)\n",
    "# count.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "count1 = collections.Counter(tokens1)\n",
    "# count1.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t, '\\n')\n",
    "t = Format.remove_hashtags(t)\n",
    "print(t, '\\n')\n",
    "t = Format.remove_mentions(t)\n",
    "print(t, '\\n')\n",
    "t = remove_stopwords(t)\n",
    "print(t, '\\n')\n",
    "t = Format.remove_picture_links(t)\n",
    "print(t, '\\n')\n",
    "t = t.translate(str.maketrans('','',string.punctuation + '—' + '“' + '…'))\n",
    "print(t, '\\n')\n",
    "t.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = test_tweets[73][1]\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = Format.remove_picture_links(tweet_text)\n",
    "print(tweet_text, '\\n')\n",
    "tweet_text = tweet_text.lower()\n",
    "print(tweet_text, '\\n')\n",
    "tweet_text = Format.remove_hashtags(tweet_text)\n",
    "print(tweet_text, '\\n')\n",
    "tweet_text = Format.remove_mentions(tweet_text)\n",
    "print(tweet_text, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_test_users = aws_conn.get_users_by_pol_label('conservative')\n",
    "libs_test_users = aws_conn.get_users_by_pol_label('liberal')\n",
    "cons_train_users = local_conn.get_users_by_pol_label('conservative')\n",
    "libs_train_users = local_conn.get_users_by_pol_label('liberal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "29\n",
      "258\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "print(len(cons_test_users))\n",
    "print(len(libs_test_users))\n",
    "print(len(cons_train_users))\n",
    "print(len(libs_train_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('sentedcruz', 1074480192, '1074480192', 'conservative', None)\n",
    "corpus = []\n",
    "for i, user in enumerate(cons_train_users):\n",
    "    tweets = local_conn.get_all_tweets_by(user[0])\n",
    "    tweets = [x[1] for x in tweets]\n",
    "    tweets = \" \".join(tweets)\n",
    "    tweets = denoise_tweet(tweets)\n",
    "    corpus.append((user[0],tweets, user[3]))\n",
    "    \n",
    "for user in libs_train_users:\n",
    "    tweets = local_conn.get_all_tweets_by(user[0])\n",
    "    tweets = [x[1] for x in tweets]\n",
    "    tweets = \" \".join(tweets)\n",
    "    tweets = denoise_tweet(tweets)\n",
    "    corpus.append((user[0], tweets, user[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, user in enumerate(cons_test_users):\n",
    "    tweets = local_conn.get_all_tweets_by(user[0])\n",
    "    tweets = [x[1] for x in tweets]\n",
    "    tweets = \" \".join(tweets)\n",
    "    tweets = denoise_tweet(tweets)\n",
    "    corpus.append((user[0], tweets, user[3]))\n",
    "    \n",
    "for i, user in enumerate(libs_test_users):\n",
    "    tweets = local_conn.get_all_tweets_by(user[0])\n",
    "    tweets = [x[1] for x in tweets]\n",
    "    tweets = \" \".join(tweets)\n",
    "    tweets = denoise_tweet(tweets)\n",
    "    corpus.append((user[0], tweets, user[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for row in corpus:\n",
    "    data.append(row[1])\n",
    "    labels.append((row[0], row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = 0.5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_username = []\n",
    "y_train_label = []\n",
    "\n",
    "for y in y_train:\n",
    "    y_train_username.append(y[0])\n",
    "    y_train_label.append(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train_username))\n",
    "print(len(y_train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_username = []\n",
    "y_test_label = []\n",
    "\n",
    "for y in y_test:\n",
    "    y_test_username.append(y[0])\n",
    "    y_test_label.append(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n",
      "315\n"
     ]
    }
   ],
   "source": [
    "print(len(y_test_username))\n",
    "print(len(y_test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = test_data + train_data\n",
    "# labels = test_labels + train_labels\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature vectors \n",
    "vectorizer = TfidfVectorizer(min_df=4, max_df=0.9)\n",
    "# Train the feature vectors\n",
    "train_vectors = vectorizer.fit_transform(x_train) #(train_data)\n",
    "# Apply model on test data \n",
    "test_vectors = vectorizer.transform(x_test)#(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform classification with SVM, kernel=linear \n",
    "model = svm.SVC(kernel='linear') \n",
    "model.fit(train_vectors, y_train_label) \n",
    "prediction = model.predict(test_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wonkroom conservative\n",
      "jbarro liberal\n",
      "senatortester conservative\n",
      "sanfordbishop conservative\n",
      "staceyplaskett conservative\n",
      "mindyfinn liberal\n",
      "repbenmcadams conservative\n",
      "repronkind conservative\n",
      "obsoletedogma conservative\n",
      "chrislynnhedges conservative\n",
      "senamyklobuchar conservative\n",
      "repedcase conservative\n",
      "repgolden conservative\n",
      "tamikadmallory conservative\n",
      "senatemajldr conservative\n",
      "senatorsinema conservative\n",
      "repcindyaxne conservative\n",
      "chrismurphyct conservative\n",
      "ezraklein conservative\n",
      "bobbyscott conservative\n",
      "kairyssdal conservative\n",
      "heerjeet conservative\n",
      "deray conservative\n",
      "julietlapidos conservative\n",
      "daveloebsack conservative\n",
      "repbrianfitz liberal\n",
      "neonflag conservative\n",
      "mariodb liberal\n",
      "collinpeterson conservative\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(prediction):\n",
    "    if y_test_label[i] != pred:\n",
    "        print(y_test_username[i], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "conservative       0.86      0.97      0.91       154\n",
      "     liberal       0.97      0.84      0.90       161\n",
      "\n",
      "    accuracy                           0.91       315\n",
      "   macro avg       0.91      0.91      0.91       315\n",
      "weighted avg       0.92      0.91      0.91       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test_label, prediction))\n",
    "# print(len(y_test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
